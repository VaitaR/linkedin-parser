{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium_stealth import stealth\n",
    "import time\n",
    "import undetected_chromedriver as uc\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "my_email = config.email\n",
    "my_password = config.password\n",
    "linkedin_link = config.linkedin_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add check about internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2023-05-18 13:38:16.803417\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now() \n",
    "print('Start time: ', start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login and pass placed\n",
      "login ready\n"
     ]
    }
   ],
   "source": [
    "# driver = uc.Chrome(use_subprocess=True)#, headless = True)\n",
    "driver = uc.Chrome(use_subprocess=True, headless = True)\n",
    "# detection test\n",
    "# driver.get('https://nowsecure.nl')\n",
    "driver.get(url = 'https://www.linkedin.com/login')\n",
    "WebDriverWait(driver, 30).until(ec.presence_of_element_located((By.ID, \"username\")))\n",
    "driver.find_element(By.ID, \"username\").send_keys(my_email)\n",
    "driver.find_element(By.ID, \"password\").send_keys(my_password)\n",
    "print('login and pass placed')\n",
    "driver.find_element(By.CLASS_NAME, \"login__form_action_container \").click()\n",
    "print('login ready')\n",
    "# work long time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytics page have problems\n"
     ]
    }
   ],
   "source": [
    "# open link\n",
    "try:\n",
    "    driver.get(url = f'https://www.linkedin.com/dashboard/')\n",
    "    WebDriverWait(driver, 30).until(ec.presence_of_element_located((By.CLASS_NAME, 'pcd-analytics-view-item')))\n",
    "\n",
    "    # profile page base numbers\n",
    "    score = driver.find_elements(By.CLASS_NAME, 'pcd-analytics-view-item')\n",
    "\n",
    "    impressions = score[0].text.split('\\n')[0]\n",
    "    print(impressions, 'post impressions past 7 days(?)')\n",
    "\n",
    "    followers = score[1].text.split('\\n')[0].replace(\",\", \"\")\n",
    "    print(followers, 'total followers') \n",
    "\n",
    "    views = score[2].text.split('\\n')[0] \n",
    "    print(views, 'profiles viewers past 90 days')\n",
    "\n",
    "    searchs = score[3].text.split('\\n')[0] \n",
    "    print(searchs, 'search appearances previous week') \n",
    "except:\n",
    "    print('analytics page have problems')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'464'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[2].text.split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search period:  2023-05-09 00:00:00  -  2023-05-16 00:00:00\n",
      "-----------------\n",
      "\n",
      "Analyst\n",
      "-----------------\n",
      "\n",
      "['Software Developer 11.1%', 'Business Analyst 8.1%', 'Founder 7.1%', 'Administrative Employee 5.1%', 'Recruiter 5.1%']\n",
      "['Wise', 'Tinkoff ', 'National Research University â€” Higher School of Economics', 'Crypto.com', 'Nuvei']\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "driver.get(url = 'https://www.linkedin.com/analytics/search-appearances/')\n",
    "WebDriverWait(driver, 30).until(ec.presence_of_element_located((By.CLASS_NAME, 'member-analytics-addon-bar-chart__row')))\n",
    "\n",
    "\n",
    "# search period parsing\n",
    "try:\n",
    "    search_period = driver.find_element(By.CLASS_NAME, 'member-analytics-addon-analytics-view__subtitle').text\n",
    "    dt1 = parse(search_period.split('between ')[1].split(' - ')[0])\n",
    "    dt2 = parse(search_period.split('between ')[1].split(' - ')[1])\n",
    "    if dt1 > dt2:\n",
    "        dt1 = dt1 - relativedelta(years = 1)\n",
    "    print('Search period: ', dt1, ' - ', dt2)\n",
    "    print('-----------------\\n')\n",
    "except:\n",
    "    print('No search period or problems with search period')\n",
    "    print('-----------------\\n')\n",
    "\n",
    "try: \n",
    "    keywords = []\n",
    "    score = driver.find_elements(By.CLASS_NAME, 'member-analytics-addon__cta-list-item')\n",
    "    for i in score:\n",
    "        print(i.text)\n",
    "        keywords.append(i.text)\n",
    "    print('-----------------\\n')\n",
    "except:\n",
    "    print('No keywords or problems with keywords')\n",
    "    print('-----------------\\n')\n",
    "\n",
    "pattern = re.compile(r'\\b\\b\\d{1,2}.\\d{1,2}%')\n",
    "pattern2 = re.compile(r'\\b\\b\\d{1,2}%')\n",
    "companies_list = []\n",
    "job_titles_list = []\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 30).until(ec.presence_of_element_located((By.CLASS_NAME, 'member-analytics-addon-bar-chart__row')))\n",
    "    score = driver.find_elements(By.CLASS_NAME, 'member-analytics-addon-bar-chart__row')\n",
    "    for i in score:\n",
    "        if pattern.findall(i.text) or pattern2.findall(i.text):\n",
    "            job_titles_list.append(i.text)\n",
    "        else:\n",
    "            companies_list.append(i.text)\n",
    "    print(job_titles_list)\n",
    "    print(companies_list)\n",
    "    print('-----------------\\n')\n",
    "except:\n",
    "    print('No companies or problems with companies')\n",
    "    print('-----------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssi page downloaded\n",
      "50  - Current Social Selling Index\n",
      "18.13  - Establish your professional brand\n",
      "8.67  - Find the right people\n",
      "7.04  - Engage with insights\n",
      "16.2  - Build relationships\n",
      "\n",
      "32  - People in your industry\n",
      "33  - People in your network\n",
      "\n",
      "11  - Top % Industry SSI rank\n",
      "11  - Top % Network SSI rank\n"
     ]
    }
   ],
   "source": [
    "driver.get(url = 'https://www.linkedin.com/sales/ssi')\n",
    "# WebDriverWait(driver, 10).until(ec.presence_of_element_located((By.TAG_NAME, \"html\")))\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(ec.presence_of_element_located((By.ID, \"content-main\")))\n",
    "    print('ssi page downloaded')\n",
    "except:\n",
    "    print('element for check was not found')\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "intro = soup.find_all('span', {'class': 'ssi-score__value block mb-3 t-black t-light'})\n",
    "\n",
    "index = intro[0].get_text(strip = True)\n",
    "print(index, ' - Current Social Selling Index')\n",
    "\n",
    "brand = intro[1].get_text(strip = True)\n",
    "print(brand, ' - Establish your professional brand')\n",
    "\n",
    "find_people = intro[2].get_text(strip = True)\n",
    "print(find_people, ' - Find the right people')\n",
    "\n",
    "engage = intro[3].get_text(strip = True)\n",
    "print(engage, ' - Engage with insights')\n",
    "\n",
    "relationships = intro[4].get_text(strip = True)\n",
    "print(relationships, ' - Build relationships')\n",
    "print()\n",
    "\n",
    "people_industry = intro[5].get_text(strip = True)\n",
    "print(people_industry, ' - People in your industry')\n",
    "people_network = intro[6].get_text(strip = True)\n",
    "print(people_network, ' - People in your network')\n",
    "print()\n",
    "\n",
    "intro = soup.find_all('div', {'class': 'ssi-rank ssi-report__container group-scores-count--2 container-plain flex flex-1'})\n",
    "industry_ssi_rank = intro[0].find_all(\"span\")[1].get_text(strip = True)\n",
    "print(industry_ssi_rank, ' - Top % Industry SSI rank')\n",
    "\n",
    "network_ssi_rank = intro[1].find_all(\"span\")[1].get_text(strip = True)\n",
    "print(network_ssi_rank, ' - Top % Network SSI rank')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-18 10:21:34\n",
      "script execution time  0:00:23.918762\n"
     ]
    }
   ],
   "source": [
    "script_time = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(script_time)\n",
    "print('script execution time ',datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "List = [script_time, views, impressions, searchs, index, brand, find_people, engage, relationships, people_industry, people_network, industry_ssi_rank, network_ssi_rank, keywords,companies_list, job_titles_list, dt1, dt2, followers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('linkedin_parsing_results.csv', 'a') as f_object:\n",
    " \n",
    "    writer_object = writer(f_object)\n",
    "    writer_object.writerow(List)\n",
    "    f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x97 in position 71484: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vaitar\\Desktop\\git_projects_portfolio\\linkedin parser\\linkedin_parser.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vaitar/Desktop/git_projects_portfolio/linkedin%20parser/linkedin_parser.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mlinkedin_parsing_results.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vaitar/Desktop/git_projects_portfolio/linkedin%20parser/linkedin_parser.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mtail()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x97 in position 71484: invalid start byte"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('linkedin_parsing_results.csv')\n",
    "# df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
